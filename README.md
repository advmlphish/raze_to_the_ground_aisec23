# Raze to the Ground: Query-Efficient Adversarial HTML Attacks on Machine-Learning Phishing Webpage Detectors (AISec '23)

This repository contains the source code of the paper _Raze to the Ground: Query-Efficient Adversarial HTML Attacks on Machine-Learning Phishing Webpage Detectors_ accepted
at the 16th ACM Workshop on Artificial Intelligence and Security (AISec '23), co-located with [ACM CCS 2023](https://www.sigsac.org/ccs/CCS2023/).  

The related pre-print is available on ArXiv: [https://arxiv.org/abs/2310.03166](https://arxiv.org/abs/2310.03166).

## Organization
The source code is organized as follows. The `src/` directory includes the following files:
* `extract_features_html.py` includes the same source code that has been refactored using the [Black formatter](https://black.readthedocs.io/en/stable/) and improved to make it more pythonic.
   Moreover, we also added the following functions:
   - `extract_features_phishing()` to extract the features as a Numpy array. The user can choose the type of features: html, url or all (html + url).
   - `build_phishing_test_data_info()` to prepare the test set (based on [DeltaPhish](https://link.springer.com/chapter/10.1007/978-3-319-66402-6_22)) to be used for the experiments.

* `manipulations.py` contains the source code of the proposed HTML adversarial manipulations.

* `optimizer.py` contains the source code of the proposed black-box optimizer.

* `model.py` implements a wrapper for Tensorflow and Scikit-learn models.

Moreover, the root directory of the repository includes the following scripts to run the adversarial attacks:
* `run_adv_attacks.py` contains the source code to generate adversarial phishing webpage against a taget machine-learning model.

* `run_experiments.py` contains the source code to run the experiments. It is based on the source code of [SpacePhish](https://github.com/hihey54/acsac22_spacephish/tree/main).

In the root directory you can also find the output of the experiments based on the source code of [SpacePhish](https://github.com/hihey54/acsac22_spacephish/tree/main).
In particular, we release:
* the output of the experiments for each ML-PWD in the `experiments/` folder.

* the `experiments_analysis.ipynb` Jupyter notebook including the plots that report how the detection rate (DR) at 1% False Positive Rate (FPR) changes during the optimization w.r.t. the number of queries, considering the best sequence of manipulations.

## Instructions
To quickly experiment with our project, we have released the pre-trained models in the `models` directory of this repository.  
They have been trained on the _DeltaPhish_ dataset using the source code provided in the [SpacePhish repository](https://github.com/hihey54/acsac22_spacephish/tree/main).  
Then, you need to create a Python virtual environment (venv) and install the required packages using the following commands (adjust the path of the venv according to your setup):
```
python3 -m venv $HOME/venv_adv_phishing
source $HOME/venv_adv_phishing activate
python -m pip install -r requirements.txt
```
The next step is to download the _DeltaPhish_ dataset.
As described in the _SpacePhish_ repository (see [get_data.md](https://github.com/hihey54/acsac22_spacephish/blob/main/get_data.md)), you can dowload it using [this link](https://drive.google.com/drive/folders/1k_aqmk5CTlhxlGfrg4jRSG5RxyX0NB9w?usp=sharing).
The password is "yy123" (without quotes).  
The last step to complete the setup is to set the `data_base_path` and `models_path` configuration variables in the `run_experiments.py` file according to your environment.  
They should point to the dataset used in _SpacePhish_ and the folder with the trained ML models, respectively.  
At this point you are ready to run the HTML adversarial attacks against the pre-trained models:
```
python run_experiments.py
```

Based on the above steps, you can find the results in the `experiments/` folder.  
Please note that for each model, we only provide the JSON file including, for each sample, the full trace of the confidence score w.r.t. the number of queries, which can be used to plot the security evaluation curves (refer to the plots in `experiments_analysis.ipynb`).  
In addition, in the `samples/` directory, we provide 5 samples of phishing webpages along with their corresponding optimized adversarial examples (marked with names ending with `_adv`) optimized on the Random Forest model trained on the full set of features, i.e., $RF$  $F^{c}$.  
If needed, the adversarial phishing webpages of all samples in the test set can be generated by following the steps described above.  
To verify whether the generated adversarial phishing webpages match the rendering of their respective phishing samples, we have included the `check_rendering.py` Python script.  
This script renders the phishing webpage and its corresponding adversarial example in the Google Chrome browser, captures their screenshots, and computes their SHA-256 checksum to check if they are the same.

Finally, if you want to train them on your own, we recommend to follow the instructions provided in the [SpacePhish repository](https://github.com/hihey54/acsac22_spacephish/tree/main).  
Once you have trained the ML models using the Jupyter notebooks provided in the _ml\_folder_ of the [SpacePhish repository](https://github.com/hihey54/acsac22_spacephish/tree/main), save them according to the naming convention used in this project (refer to the `models_info` dict in `run_experiments.py`).
